{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import nltk.sentiment.util\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "import re\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "import os\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../amazon_reviews_us_Grocery_v1_00_sentiment.csv').sample(100000)\n",
    "\n",
    "df = df.drop([\"marketplace\", \"customer_id\", \"product_parent\", \"product_category\", \"review_date\"], axis=1)\n",
    "\n",
    "df = df[~df['review_body'].isnull()]\n",
    "\n",
    "df['review_body'] = df['review_headline'] + '. ' + df['review_body']\n",
    "\n",
    "df[\"health_hazard\"] = np.nan\n",
    "\n",
    "df = df.set_index(\"review_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>health_hazard</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RLSO7CW3S1GOT</th>\n",
       "      <td>B004VD6S8K</td>\n",
       "      <td>Barr's Irn-Bru</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>In Bru</td>\n",
       "      <td>In Bru. My hubby loved the Iron Bru he said th...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RYRKM8U8HPUOK</th>\n",
       "      <td>B00C75UT0C</td>\n",
       "      <td>Soul Sprout, by Two Moms Sprouted Grain Free C...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Great by itself</td>\n",
       "      <td>Great by itself. This is the most unique grano...</td>\n",
       "      <td>0.556250</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R1R7UU0N0KGXX3</th>\n",
       "      <td>B00FPLGA6C</td>\n",
       "      <td>Chef Boyardee Pepperoni Pizza Maker Kit, 31.85...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Five Stars. Lots of fun!</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RITECYC69L97R</th>\n",
       "      <td>B0004N0T86</td>\n",
       "      <td>McCormick Perfect Pinch Lemon &amp; Pepper Seasoni...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Lemon....yummy!</td>\n",
       "      <td>Lemon....yummy!. This lemon pepper has a reall...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2DOF1LVJGS18M</th>\n",
       "      <td>B00M0NEK3S</td>\n",
       "      <td>Starbucks Variety Coffee K-Cup Featuring 3 Dar...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Delicious!</td>\n",
       "      <td>Delicious!. Nice variety of dark roasts...deli...</td>\n",
       "      <td>0.103125</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF9EF902NTRZR</th>\n",
       "      <td>B007K6SSTC</td>\n",
       "      <td>Grove Square Cappuccino, Single Serve Cup for ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>it is ok</td>\n",
       "      <td>it is ok. it tastes ok, but sometimes if you m...</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RI76ISLK745TE</th>\n",
       "      <td>B00C3M61AQ</td>\n",
       "      <td>Nestle Crunch Girl Scout Candy Bars, Thin Mint...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>A great minty treat</td>\n",
       "      <td>A great minty treat. While these are made by N...</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R7ABK0IR8WQ05</th>\n",
       "      <td>B001BMDF1M</td>\n",
       "      <td>Health Valley Health Valley Organic Soup, Vege...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>no-salt healthy valley vegetable soup</td>\n",
       "      <td>no-salt healthy valley vegetable soup. This is...</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R24EDDQ9FV38CV</th>\n",
       "      <td>B000SAPXRW</td>\n",
       "      <td>Davidson's Tea Bulk</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Love this Tea!</td>\n",
       "      <td>Love this Tea!. I'm fairly picky about my tea....</td>\n",
       "      <td>0.350298</td>\n",
       "      <td>0.516964</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RD9J8WBJUQUJC</th>\n",
       "      <td>B0009XQTA8</td>\n",
       "      <td>Campbell's Soup on the Go, 10.75 Ounce (Pack o...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>OK for a broth</td>\n",
       "      <td>OK for a broth. You won't find any chunks of b...</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                product_id                                      product_title  \\\n",
       "review_id                                                                       \n",
       "RLSO7CW3S1GOT   B004VD6S8K                                     Barr's Irn-Bru   \n",
       "RYRKM8U8HPUOK   B00C75UT0C  Soul Sprout, by Two Moms Sprouted Grain Free C...   \n",
       "R1R7UU0N0KGXX3  B00FPLGA6C  Chef Boyardee Pepperoni Pizza Maker Kit, 31.85...   \n",
       "RITECYC69L97R   B0004N0T86  McCormick Perfect Pinch Lemon & Pepper Seasoni...   \n",
       "R2DOF1LVJGS18M  B00M0NEK3S  Starbucks Variety Coffee K-Cup Featuring 3 Dar...   \n",
       "...                    ...                                                ...   \n",
       "RF9EF902NTRZR   B007K6SSTC  Grove Square Cappuccino, Single Serve Cup for ...   \n",
       "RI76ISLK745TE   B00C3M61AQ  Nestle Crunch Girl Scout Candy Bars, Thin Mint...   \n",
       "R7ABK0IR8WQ05   B001BMDF1M  Health Valley Health Valley Organic Soup, Vege...   \n",
       "R24EDDQ9FV38CV  B000SAPXRW                                Davidson's Tea Bulk   \n",
       "RD9J8WBJUQUJC   B0009XQTA8  Campbell's Soup on the Go, 10.75 Ounce (Pack o...   \n",
       "\n",
       "                star_rating  helpful_votes  total_votes vine  \\\n",
       "review_id                                                      \n",
       "RLSO7CW3S1GOT             5              0            0    N   \n",
       "RYRKM8U8HPUOK             5              1            1    N   \n",
       "R1R7UU0N0KGXX3            5              0            0    N   \n",
       "RITECYC69L97R             5              1            1    N   \n",
       "R2DOF1LVJGS18M            5              0            0    N   \n",
       "...                     ...            ...          ...  ...   \n",
       "RF9EF902NTRZR             4              0            0    N   \n",
       "RI76ISLK745TE             5              5            5    N   \n",
       "R7ABK0IR8WQ05             5              0            0    N   \n",
       "R24EDDQ9FV38CV            5              0            0    N   \n",
       "RD9J8WBJUQUJC             3              0            0    N   \n",
       "\n",
       "               verified_purchase                        review_headline  \\\n",
       "review_id                                                                 \n",
       "RLSO7CW3S1GOT                  Y                                 In Bru   \n",
       "RYRKM8U8HPUOK                  Y                        Great by itself   \n",
       "R1R7UU0N0KGXX3                 Y                             Five Stars   \n",
       "RITECYC69L97R                  Y                        Lemon....yummy!   \n",
       "R2DOF1LVJGS18M                 Y                             Delicious!   \n",
       "...                          ...                                    ...   \n",
       "RF9EF902NTRZR                  Y                               it is ok   \n",
       "RI76ISLK745TE                  N                    A great minty treat   \n",
       "R7ABK0IR8WQ05                  Y  no-salt healthy valley vegetable soup   \n",
       "R24EDDQ9FV38CV                 Y                         Love this Tea!   \n",
       "RD9J8WBJUQUJC                  Y                         OK for a broth   \n",
       "\n",
       "                                                      review_body  polarity  \\\n",
       "review_id                                                                     \n",
       "RLSO7CW3S1GOT   In Bru. My hubby loved the Iron Bru he said th...  0.300000   \n",
       "RYRKM8U8HPUOK   Great by itself. This is the most unique grano...  0.556250   \n",
       "R1R7UU0N0KGXX3                           Five Stars. Lots of fun!  0.375000   \n",
       "RITECYC69L97R   Lemon....yummy!. This lemon pepper has a reall...  0.500000   \n",
       "R2DOF1LVJGS18M  Delicious!. Nice variety of dark roasts...deli...  0.103125   \n",
       "...                                                           ...       ...   \n",
       "RF9EF902NTRZR   it is ok. it tastes ok, but sometimes if you m...  0.183333   \n",
       "RI76ISLK745TE   A great minty treat. While these are made by N...  0.210000   \n",
       "R7ABK0IR8WQ05   no-salt healthy valley vegetable soup. This is...  0.450000   \n",
       "R24EDDQ9FV38CV  Love this Tea!. I'm fairly picky about my tea....  0.350298   \n",
       "RD9J8WBJUQUJC   OK for a broth. You won't find any chunks of b...  0.350000   \n",
       "\n",
       "                subjectivity  health_hazard  \n",
       "review_id                                    \n",
       "RLSO7CW3S1GOT       0.575000            NaN  \n",
       "RYRKM8U8HPUOK       0.641667            NaN  \n",
       "R1R7UU0N0KGXX3      0.200000            NaN  \n",
       "RITECYC69L97R       0.400000            NaN  \n",
       "R2DOF1LVJGS18M      0.350000            NaN  \n",
       "...                      ...            ...  \n",
       "RF9EF902NTRZR       0.316667            NaN  \n",
       "RI76ISLK745TE       0.285000            NaN  \n",
       "R7ABK0IR8WQ05       0.283333            NaN  \n",
       "R24EDDQ9FV38CV      0.516964            NaN  \n",
       "RD9J8WBJUQUJC       0.300000            NaN  \n",
       "\n",
       "[100000 rows x 12 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "neg_reviews = df.query(\"star_rating < 4\", engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-59-eba5c76ea0a6>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  neg_reviews[\"tokened_review\"] = all_tokens\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['br'])\n",
    "translator=str.maketrans('','',string.punctuation)\n",
    "\n",
    "#neg_reviews[\"tokened_review\"] = np.nan\n",
    "all_tokens = []\n",
    "#neg_reviews.astype({\"tokened_review\": 'object'}).dtypes\n",
    "for index, row in neg_reviews.iterrows():\n",
    "    text = row[\"review_body\"].lower()\n",
    "    text = text.translate(translator)\n",
    "    text = word_tokenize(text)\n",
    "    new_text = []\n",
    "    for token in text:\n",
    "        token = stemmer.stem(token)\n",
    "        if token not in stop_words:\n",
    "            new_text.append(token)\n",
    "    all_tokens.append(new_text)\n",
    "neg_reviews[\"tokened_review\"] = all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>health_hazard</th>\n",
       "      <th>tokened_review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RT2Y92DQLOI7V</th>\n",
       "      <td>B000LKU4XM</td>\n",
       "      <td>Road's End Organics Gluten Free Mac &amp; Chreese ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>So bad!</td>\n",
       "      <td>So bad!. I was shocked at how bad this product...</td>\n",
       "      <td>-0.117284</td>\n",
       "      <td>0.297840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[bad, wa, shock, bad, thi, product, look, tast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2KM5IIC4MULJB</th>\n",
       "      <td>B00C0WHDME</td>\n",
       "      <td>Popcorn Indiana Movie Theater Popcorn, 5.5 Ounce</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>The Worst</td>\n",
       "      <td>The Worst. While I admire the company itself a...</td>\n",
       "      <td>-0.433333</td>\n",
       "      <td>0.565278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[worst, admir, compani, ingredi, pride, selv, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R3NNXIDO22ST3X</th>\n",
       "      <td>B00HKDKUO6</td>\n",
       "      <td>Louisiana Purchase Red Beans and Rice Cup, 2 O...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>This is not good stuff. I could get some red b...</td>\n",
       "      <td>This is not good stuff. I could get some red b...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[thi, good, stuff, could, get, red, bean, thi,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R3SPI91Y0N24MC</th>\n",
       "      <td>B004EKHMXU</td>\n",
       "      <td>Healthworks Cacao Nibs Parent</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Poor taste!</td>\n",
       "      <td>Poor taste!. I've eaten many raw cacao nibs be...</td>\n",
       "      <td>0.200427</td>\n",
       "      <td>0.365812</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[poor, tast, ive, eaten, mani, raw, cacao, nib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R25DJYDTCXQZ25</th>\n",
       "      <td>B0055Z8ROQ</td>\n",
       "      <td>The Sprout House Certified Organic Non-gmo Spr...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td>Disappointed. Only half of the seeds actually ...</td>\n",
       "      <td>-0.174583</td>\n",
       "      <td>0.463333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[disappoint, onli, half, seed, actual, sprout,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R33FB4DK9QBJ4W</th>\n",
       "      <td>B004MAV8M8</td>\n",
       "      <td>Sierra Tea Organic Supermicro Grounded Matcha ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>not good flavor</td>\n",
       "      <td>not good flavor. bitter. just not a very enjoy...</td>\n",
       "      <td>-0.089231</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[good, flavor, bitter, veri, enjoy, matcha, un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R3CUH1YEGV4MPQ</th>\n",
       "      <td>B004V6A9SC</td>\n",
       "      <td>Newman's Own Con Queso Salsa, 16-Ounce (Pack o...</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>55</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>So I did find good use for it after all</td>\n",
       "      <td>So I did find good use for it after all. I bou...</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[find, good, use, bought, thi, catfish, bait, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R23FZP3HUPJQTT</th>\n",
       "      <td>B00KOPGQRW</td>\n",
       "      <td>Tabasco Brand Buffalo Hot Sauce - by McIlhenny...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>One Star</td>\n",
       "      <td>One Star. This stuff is terrible!</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[one, star, thi, stuff, terribl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2A3DRF31HIWHF</th>\n",
       "      <td>B002YR7BBI</td>\n",
       "      <td>Gluten Free Mama, Mama's Pie Crust Mix, 18-Oun...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Not my mama's pie crust</td>\n",
       "      <td>Not my mama's pie crust. Was surprised to find...</td>\n",
       "      <td>0.079583</td>\n",
       "      <td>0.370417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[mama, pie, crust, wa, surpris, find, add, man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RD9J8WBJUQUJC</th>\n",
       "      <td>B0009XQTA8</td>\n",
       "      <td>Campbell's Soup on the Go, 10.75 Ounce (Pack o...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>OK for a broth</td>\n",
       "      <td>OK for a broth. You won't find any chunks of b...</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ok, broth, wont, find, ani, chunk, beef, thi,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18435 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                product_id                                      product_title  \\\n",
       "review_id                                                                       \n",
       "RT2Y92DQLOI7V   B000LKU4XM  Road's End Organics Gluten Free Mac & Chreese ...   \n",
       "R2KM5IIC4MULJB  B00C0WHDME   Popcorn Indiana Movie Theater Popcorn, 5.5 Ounce   \n",
       "R3NNXIDO22ST3X  B00HKDKUO6  Louisiana Purchase Red Beans and Rice Cup, 2 O...   \n",
       "R3SPI91Y0N24MC  B004EKHMXU                      Healthworks Cacao Nibs Parent   \n",
       "R25DJYDTCXQZ25  B0055Z8ROQ  The Sprout House Certified Organic Non-gmo Spr...   \n",
       "...                    ...                                                ...   \n",
       "R33FB4DK9QBJ4W  B004MAV8M8  Sierra Tea Organic Supermicro Grounded Matcha ...   \n",
       "R3CUH1YEGV4MPQ  B004V6A9SC  Newman's Own Con Queso Salsa, 16-Ounce (Pack o...   \n",
       "R23FZP3HUPJQTT  B00KOPGQRW  Tabasco Brand Buffalo Hot Sauce - by McIlhenny...   \n",
       "R2A3DRF31HIWHF  B002YR7BBI  Gluten Free Mama, Mama's Pie Crust Mix, 18-Oun...   \n",
       "RD9J8WBJUQUJC   B0009XQTA8  Campbell's Soup on the Go, 10.75 Ounce (Pack o...   \n",
       "\n",
       "                star_rating  helpful_votes  total_votes vine  \\\n",
       "review_id                                                      \n",
       "RT2Y92DQLOI7V             1              0            1    N   \n",
       "R2KM5IIC4MULJB            1              0            3    N   \n",
       "R3NNXIDO22ST3X            1              0            1    N   \n",
       "R3SPI91Y0N24MC            2              0            0    N   \n",
       "R25DJYDTCXQZ25            3              2            2    N   \n",
       "...                     ...            ...          ...  ...   \n",
       "R33FB4DK9QBJ4W            2              0            0    N   \n",
       "R3CUH1YEGV4MPQ            2             40           55    N   \n",
       "R23FZP3HUPJQTT            1              0            0    N   \n",
       "R2A3DRF31HIWHF            2              1            1    N   \n",
       "RD9J8WBJUQUJC             3              0            0    N   \n",
       "\n",
       "               verified_purchase  \\\n",
       "review_id                          \n",
       "RT2Y92DQLOI7V                  N   \n",
       "R2KM5IIC4MULJB                 N   \n",
       "R3NNXIDO22ST3X                 Y   \n",
       "R3SPI91Y0N24MC                 Y   \n",
       "R25DJYDTCXQZ25                 N   \n",
       "...                          ...   \n",
       "R33FB4DK9QBJ4W                 Y   \n",
       "R3CUH1YEGV4MPQ                 N   \n",
       "R23FZP3HUPJQTT                 Y   \n",
       "R2A3DRF31HIWHF                 Y   \n",
       "RD9J8WBJUQUJC                  Y   \n",
       "\n",
       "                                                  review_headline  \\\n",
       "review_id                                                           \n",
       "RT2Y92DQLOI7V                                             So bad!   \n",
       "R2KM5IIC4MULJB                                          The Worst   \n",
       "R3NNXIDO22ST3X  This is not good stuff. I could get some red b...   \n",
       "R3SPI91Y0N24MC                                        Poor taste!   \n",
       "R25DJYDTCXQZ25                                       Disappointed   \n",
       "...                                                           ...   \n",
       "R33FB4DK9QBJ4W                                    not good flavor   \n",
       "R3CUH1YEGV4MPQ            So I did find good use for it after all   \n",
       "R23FZP3HUPJQTT                                           One Star   \n",
       "R2A3DRF31HIWHF                            Not my mama's pie crust   \n",
       "RD9J8WBJUQUJC                                      OK for a broth   \n",
       "\n",
       "                                                      review_body  polarity  \\\n",
       "review_id                                                                     \n",
       "RT2Y92DQLOI7V   So bad!. I was shocked at how bad this product... -0.117284   \n",
       "R2KM5IIC4MULJB  The Worst. While I admire the company itself a... -0.433333   \n",
       "R3NNXIDO22ST3X  This is not good stuff. I could get some red b...  0.008333   \n",
       "R3SPI91Y0N24MC  Poor taste!. I've eaten many raw cacao nibs be...  0.200427   \n",
       "R25DJYDTCXQZ25  Disappointed. Only half of the seeds actually ... -0.174583   \n",
       "...                                                           ...       ...   \n",
       "R33FB4DK9QBJ4W  not good flavor. bitter. just not a very enjoy... -0.089231   \n",
       "R3CUH1YEGV4MPQ  So I did find good use for it after all. I bou...  0.152000   \n",
       "R23FZP3HUPJQTT                  One Star. This stuff is terrible! -1.000000   \n",
       "R2A3DRF31HIWHF  Not my mama's pie crust. Was surprised to find...  0.079583   \n",
       "RD9J8WBJUQUJC   OK for a broth. You won't find any chunks of b...  0.350000   \n",
       "\n",
       "                subjectivity  health_hazard  \\\n",
       "review_id                                     \n",
       "RT2Y92DQLOI7V       0.297840            NaN   \n",
       "R2KM5IIC4MULJB      0.565278            NaN   \n",
       "R3NNXIDO22ST3X      0.550000            NaN   \n",
       "R3SPI91Y0N24MC      0.365812            NaN   \n",
       "R25DJYDTCXQZ25      0.463333            NaN   \n",
       "...                      ...            ...   \n",
       "R33FB4DK9QBJ4W      0.246154            NaN   \n",
       "R3CUH1YEGV4MPQ      0.388000            NaN   \n",
       "R23FZP3HUPJQTT      1.000000            NaN   \n",
       "R2A3DRF31HIWHF      0.370417            NaN   \n",
       "RD9J8WBJUQUJC       0.300000            NaN   \n",
       "\n",
       "                                                   tokened_review  \n",
       "review_id                                                          \n",
       "RT2Y92DQLOI7V   [bad, wa, shock, bad, thi, product, look, tast...  \n",
       "R2KM5IIC4MULJB  [worst, admir, compani, ingredi, pride, selv, ...  \n",
       "R3NNXIDO22ST3X  [thi, good, stuff, could, get, red, bean, thi,...  \n",
       "R3SPI91Y0N24MC  [poor, tast, ive, eaten, mani, raw, cacao, nib...  \n",
       "R25DJYDTCXQZ25  [disappoint, onli, half, seed, actual, sprout,...  \n",
       "...                                                           ...  \n",
       "R33FB4DK9QBJ4W  [good, flavor, bitter, veri, enjoy, matcha, un...  \n",
       "R3CUH1YEGV4MPQ  [find, good, use, bought, thi, catfish, bait, ...  \n",
       "R23FZP3HUPJQTT                   [one, star, thi, stuff, terribl]  \n",
       "R2A3DRF31HIWHF  [mama, pie, crust, wa, surpris, find, add, man...  \n",
       "RD9J8WBJUQUJC   [ok, broth, wont, find, ani, chunk, beef, thi,...  \n",
       "\n",
       "[18435 rows x 13 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    }
   ],
   "source": [
    "hazardous_words=[\"rotten\", \"mouldy\", \"moldy\", \"mold\", \"mould\", \"sick\", \"dangerous\", \"diarrhea\", \"poisoning\", \"stale\", \"contaminate\",'disease', 'disgusting', 'hospital', 'poisoning', 'hazardous', 'ill', 'mold','moldy', 'mildew', 'dangerous' 'rancid', 'smelly', 'stale', 'unhealthy', 'sick','expired','expiration']\n",
    "for word in hazardous_words:\n",
    "    neg_reviews.loc[[stemmer.stem(word) in tokened_review for tokened_review in neg_reviews[\"tokened_review\"]], \"health_hazard\"] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1989"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labeled = len(neg_reviews.query(\"health_hazard == 1\", engine=\"python\"))\n",
    "num_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    }
   ],
   "source": [
    "non_hazardous = neg_reviews.query(\"health_hazard != 1\", engine=\"python\").sample(3*num_labeled)\n",
    "for i in list(non_hazardous.index):\n",
    "    neg_reviews.loc[i, \"health_hazard\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled = neg_reviews.query(\"health_hazard == 0 or health_hazard == 1\", engine=\"python\")\n",
    "reviews = labeled.loc[:, 'tokened_review'].values\n",
    "y = labeled.loc[:, 'health_hazard'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([list(['bad', 'wa', 'shock', 'bad', 'thi', 'product', 'look', 'tast', 'noodl', 'never', 'got', 'soft', 'cook', '15', 'minut', 'suggest', '610', 'think', 'hard', 'tast', 'stale', 'far', 'befor', 'expir', 'date', 'sauc', 'oh', 'sauc', 'wa', 'grey', 'gritti', 'tast', 'like', 'rancid', 'chicken', 'broth', 'kid', 'took', 'one', 'bite', 'refus', 'eat', 'anoth', 'stomach', 'kid', 'serious', 'wa', 'gross']),\n",
      "       list(['poor', 'tast', 'ive', 'eaten', 'mani', 'raw', 'cacao', 'nib', 'befor', 'par', 'strong', 'moldi', 'tast', 'mani', 'nib', 'mayb', 'wa', 'fluke']),\n",
      "       list(['disappoint', 'onli', 'half', 'seed', 'actual', 'sprout', 'vital', 'wa', 'good', 'growth', 'wa', 'veri', 'slow', 'think', 'seed', 'sit', 'shelf', 'long']),\n",
      "       ...,\n",
      "       list(['mostli', 'broken', 'piec', 'want', 'fool', 'think', 'wa', 'eat', 'pretzel', 'stick', 'wa', 'imposs', 'bag', 'broken', 'piec']),\n",
      "       list(['buy', 'horribl', 'horribl', 'bad', 'got', 'didnt', 'mark', 'perish', 'packag', 'wa', 'instruct', 'leav', 'outsid', 'noon', 'answer']),\n",
      "       list(['ok', 'broth', 'wont', 'find', 'ani', 'chunk', 'beef', 'thi', 'good', 'broth', 'thi', 'microwav', 'contain'])],\n",
      "      dtype=object)\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(reviews)):\n",
    "    reviews[i] = ' '.join(reviews[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bad wa shock bad thi product look tast noodl never got soft cook 15 minut suggest 610 think hard tast stale far befor expir date sauc oh sauc wa grey gritti tast like rancid chicken broth kid took one bite refus eat anoth stomach kid serious wa gross',\n",
       "       'poor tast ive eaten mani raw cacao nib befor par strong moldi tast mani nib mayb wa fluke',\n",
       "       'disappoint onli half seed actual sprout vital wa good growth wa veri slow think seed sit shelf long',\n",
       "       ...,\n",
       "       'mostli broken piec want fool think wa eat pretzel stick wa imposs bag broken piec',\n",
       "       'buy horribl horribl bad got didnt mark perish packag wa instruct leav outsid noon answer',\n",
       "       'ok broth wont find ani chunk beef thi good broth thi microwav contain'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.42352139, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "matrix = TfidfVectorizer(max_features=200)\n",
    "X = matrix.fit_transform(reviews).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9411764705882353\n",
      "0.9316239316239316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier_g = GaussianNB()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier_l = LogisticRegression()\n",
    "\n",
    "classifier_g.fit(X_train, y_train)\n",
    "classifier_l.fit(X_train, y_train)\n",
    "\n",
    "# Predict Class\n",
    "y_pred_g = classifier_g.predict(X_test)\n",
    "y_pred_l = classifier_l.predict(X_test)\n",
    "\n",
    "# Accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_g = accuracy_score(y_test, y_pred_g)\n",
    "accuracy_l = accuracy_score(y_test, y_pred_l)\n",
    "print(accuracy_g)\n",
    "print(accuracy_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = neg_reviews.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actual',\n",
       " 'ad',\n",
       " 'add',\n",
       " 'almost',\n",
       " 'also',\n",
       " 'amazon',\n",
       " 'ani',\n",
       " 'anoth',\n",
       " 'anyth',\n",
       " 'arriv',\n",
       " 'aw',\n",
       " 'away',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'bag',\n",
       " 'bar',\n",
       " 'bean',\n",
       " 'becaus',\n",
       " 'befor',\n",
       " 'best',\n",
       " 'better',\n",
       " 'bit',\n",
       " 'bitter',\n",
       " 'bottl',\n",
       " 'bought',\n",
       " 'box',\n",
       " 'brand',\n",
       " 'buy',\n",
       " 'came',\n",
       " 'candi',\n",
       " 'cant',\n",
       " 'chip',\n",
       " 'chocol',\n",
       " 'coffe',\n",
       " 'come',\n",
       " 'compani',\n",
       " 'contain',\n",
       " 'cooki',\n",
       " 'could',\n",
       " 'cup',\n",
       " 'date',\n",
       " 'day',\n",
       " 'didnt',\n",
       " 'differ',\n",
       " 'disappoint',\n",
       " 'disgust',\n",
       " 'doe',\n",
       " 'doesnt',\n",
       " 'dont',\n",
       " 'dri',\n",
       " 'drink',\n",
       " 'eat',\n",
       " 'enjoy',\n",
       " 'enough',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'everi',\n",
       " 'expect',\n",
       " 'expens',\n",
       " 'expir',\n",
       " 'feel',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'first',\n",
       " 'flavor',\n",
       " 'food',\n",
       " 'found',\n",
       " 'free',\n",
       " 'fresh',\n",
       " 'fruit',\n",
       " 'get',\n",
       " 'gift',\n",
       " 'give',\n",
       " 'go',\n",
       " 'good',\n",
       " 'got',\n",
       " 'great',\n",
       " 'green',\n",
       " 'ha',\n",
       " 'half',\n",
       " 'hard',\n",
       " 'high',\n",
       " 'hope',\n",
       " 'horribl',\n",
       " 'hot',\n",
       " 'howev',\n",
       " 'id',\n",
       " 'ill',\n",
       " 'im',\n",
       " 'ingredi',\n",
       " 'item',\n",
       " 'ive',\n",
       " 'kind',\n",
       " 'know',\n",
       " 'label',\n",
       " 'last',\n",
       " 'less',\n",
       " 'like',\n",
       " 'littl',\n",
       " 'local',\n",
       " 'look',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'made',\n",
       " 'make',\n",
       " 'mani',\n",
       " 'may',\n",
       " 'mayb',\n",
       " 'milk',\n",
       " 'mix',\n",
       " 'money',\n",
       " 'month',\n",
       " 'much',\n",
       " 'need',\n",
       " 'never',\n",
       " 'new',\n",
       " 'nice',\n",
       " 'noth',\n",
       " 'oil',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'one',\n",
       " 'onli',\n",
       " 'open',\n",
       " 'order',\n",
       " 'organ',\n",
       " 'pack',\n",
       " 'packag',\n",
       " 'peopl',\n",
       " 'piec',\n",
       " 'powder',\n",
       " 'pretti',\n",
       " 'price',\n",
       " 'probabl',\n",
       " 'problem',\n",
       " 'product',\n",
       " 'purchas',\n",
       " 'put',\n",
       " 'qualiti',\n",
       " 'quit',\n",
       " 'read',\n",
       " 'real',\n",
       " 'realli',\n",
       " 'receiv',\n",
       " 'recommend',\n",
       " 'return',\n",
       " 'review',\n",
       " 'said',\n",
       " 'salt',\n",
       " 'sauc',\n",
       " 'say',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'ship',\n",
       " 'sinc',\n",
       " 'size',\n",
       " 'small',\n",
       " 'smell',\n",
       " 'someth',\n",
       " 'stale',\n",
       " 'star',\n",
       " 'stick',\n",
       " 'still',\n",
       " 'store',\n",
       " 'strong',\n",
       " 'stuff',\n",
       " 'sugar',\n",
       " 'sure',\n",
       " 'sweet',\n",
       " 'take',\n",
       " 'tast',\n",
       " 'tea',\n",
       " 'terribl',\n",
       " 'textur',\n",
       " 'thi',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'though',\n",
       " 'thought',\n",
       " 'three',\n",
       " 'time',\n",
       " 'tri',\n",
       " 'two',\n",
       " 'use',\n",
       " 'veri',\n",
       " 'wa',\n",
       " 'want',\n",
       " 'wasnt',\n",
       " 'wast',\n",
       " 'water',\n",
       " 'way',\n",
       " 'well',\n",
       " 'whi',\n",
       " 'whole',\n",
       " 'wont',\n",
       " 'work',\n",
       " 'worth',\n",
       " 'would',\n",
       " 'year']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-254711d9e460>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtrial_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrial_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrial_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtrial_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "trial = neg_reviews\n",
    "trial_x = trial.loc[:,\"tokened_review\"].values\n",
    "for i in range(len(trial_x)):\n",
    "    trial_x[i] = ' '.join(trial_x[i])\n",
    "trial_X = matrix.fit_transform(trial_x).toarray()\n",
    "trial_y = classifier.predict(trial_X)\n",
    "trial_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_reviews[\"health_hazard\"] = trial_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "neg_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dangerous = neg_reviews.query(\"health_hazard == 1\", engine=\"python\")\n",
    "dangerous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA\n",
    "data_filtered = dangerous['review_body'].values\n",
    "pprint.pprint(data_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.lower()\n",
    "        sentence = sentence.translate(translator)\n",
    "        yield(nltk.word_tokenize(str(sentence)))\n",
    "\n",
    "data_words = list(sent_to_words(data_filtered))\n",
    "clean_data = []\n",
    "for i in range(len(data_words)):\n",
    "    clean_review = []\n",
    "    for j in range(len(data_words[i])):\n",
    "        if data_words[i][j] not in stop_words:\n",
    "            clean_review.append(data_words[i][j])\n",
    "    clean_data.append(clean_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(clean_data)\n",
    "# Create Corpus\n",
    "texts = clean_data\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# View\n",
    "pprint.pprint(corpus[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# number of topics\n",
    "num_topics = 5\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics,\n",
    "                                       minimum_probability=0.1,\n",
    "                                       workers=3,\n",
    "                                       passes=2)\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint.pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from itertools import chain\n",
    "#lda_corpus = lda_model[corpus]\n",
    "\n",
    "# Find the threshold, let's set the threshold to be 1/#clusters,\n",
    "# To prove that the threshold is sane, we average the sum of all probabilities:\n",
    "#scores = list(chain(*[[score for topic_id,score in topic] for topic in [doc for doc in lda_corpus]]))\n",
    "#threshold = sum(scores)/len(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "data_vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "\n",
    "pyLDAvis.display(data_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
